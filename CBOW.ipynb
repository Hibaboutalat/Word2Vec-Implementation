{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c481813-6807-41a5-890f-f42ffb9794e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # enlever la ponctuation\n",
    "    words = text.split()\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df480fb-f594-4381-8ee8-0d9561eab612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(words):\n",
    "    vocab = list(set(words))\n",
    "    word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "    idx2word = {i: w for w, i in word2idx.items()}\n",
    "    return vocab, word2idx, idx2word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0466ce00-444b-4d8d-a07c-0bba2707f60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cbow_pairs(words, window_size):\n",
    "    pairs = []\n",
    "    for idx in range(window_size, len(words) - window_size):\n",
    "        context = []\n",
    "        for i in range(-window_size, window_size + 1):\n",
    "            if i != 0:\n",
    "                context.append(words[idx + i])\n",
    "        target = words[idx]\n",
    "        pairs.append((context, target))\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "475e1ec1-1f2b-4dcf-89b6-255e45e3fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_vector(word, word2idx, vocab_size):\n",
    "    vec = np.zeros(vocab_size)\n",
    "    vec[word2idx[word]] = 1\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cfa2864-aa69-49fb-ae84-7f326bbe2634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(pairs, word2idx, vocab_size):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for context, target in pairs:\n",
    "        context_vec = np.sum([one_hot_vector(w, word2idx, vocab_size) for w in context], axis=0)\n",
    "        target_vec = one_hot_vector(target, word2idx, vocab_size)\n",
    "        X_train.append(context_vec)\n",
    "        y_train.append(target_vec)\n",
    "    return np.array(X_train), np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c672e818-f43b-4c27-84c9-79a8e6ee99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "class CBOW:\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        self.W1 = np.random.rand(vocab_size, embedding_dim)\n",
    "        self.W2 = np.random.rand(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.h = np.dot(x, self.W1)\n",
    "        self.u = np.dot(self.h, self.W2)\n",
    "        self.y_pred = softmax(self.u)\n",
    "        return self.y_pred\n",
    "\n",
    "    def backward(self, x, y_true, learning_rate):\n",
    "        e = self.y_pred - y_true  # erreur\n",
    "        dW2 = np.outer(self.h, e)\n",
    "        dW1 = np.outer(x, np.dot(self.W2, e))\n",
    "\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.W2 -= learning_rate * dW2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "776ac400-0104-49f6-992a-77078b67f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, epochs=100, learning_rate=0.1):\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        for i in range(len(X)):\n",
    "            y_pred = model.forward(X[i])\n",
    "            model.backward(X[i], y[i], learning_rate)\n",
    "            loss += -np.log(y_pred[np.argmax(y[i])])\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss/len(X):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f515974-fe54-4a42-94fb-1e79fbd2088f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 4.3363\n",
      "Epoch 10, Loss: 1.5539\n",
      "Epoch 20, Loss: 0.2866\n",
      "Epoch 30, Loss: 0.1023\n",
      "Epoch 40, Loss: 0.0579\n",
      "Epoch 50, Loss: 0.0394\n",
      "Epoch 60, Loss: 0.0295\n",
      "Epoch 70, Loss: 0.0234\n",
      "Epoch 80, Loss: 0.0193\n",
      "Epoch 90, Loss: 0.0163\n"
     ]
    }
   ],
   "source": [
    "# Exemple d’un paragraphe\n",
    "paragraph = \"\"\"\n",
    "Le traitement du langage naturel permet aux machines de comprendre le langage humain.\n",
    "Word2Vec est un modèle populaire pour représenter les mots sous forme de vecteurs.\n",
    "\"\"\"\n",
    "\n",
    "# Pipeline complet\n",
    "words = preprocess_text(paragraph)\n",
    "vocab, word2idx, idx2word = build_vocab(words)\n",
    "pairs = generate_cbow_pairs(words, window_size=2)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "X_train, y_train = create_training_data(pairs, word2idx, vocab_size)\n",
    "cbow_model = CBOW(vocab_size=vocab_size, embedding_dim=10)\n",
    "\n",
    "train(cbow_model, X_train, y_train, epochs=100, learning_rate=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "314a9b44-1303-48d7-a845-a269ce21a979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding de 'vecteurs' : [-0.63304883  0.3104305   0.46244799  0.03192678  0.37470317  0.86157857\n",
      "  0.68808391  0.50728333  1.08083407  0.81998858]\n"
     ]
    }
   ],
   "source": [
    "# Embedding du mot \"vecteurs\"\n",
    "word = \"vecteurs\"\n",
    "embedding = cbow_model.W1[word2idx[word]]\n",
    "print(f\"Embedding de '{word}' :\", embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23373d9e-886d-44cf-9bee-406c4522cae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
